{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4b3a5c7f-abfd-4e4d-9b18-73bbe6c26d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "11a7f3ad-50ca-4b93-b6d3-4f9c9e13710a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"espanol.txt\",\"r\",encoding=\"utf-8\") as f:\n",
    "    raw_text=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a0f2e50e-f499-4e54-86c5-74ba1c0d215f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'!': 0, ',': 1, '.': 2, ':': 3, '?': 4, 'A': 5, 'Al': 6, 'Aprende': 7, 'Camina': 8, 'Carla': 9, 'Come': 10, 'Comen': 11, 'Corren': 12, 'Después': 13, 'El': 14, 'Ella': 15, 'En': 16, 'Es': 17, 'Escribe': 18, 'Hablan': 19, 'Juegan': 20, 'La': 21, 'Laura': 22, 'Le': 23, 'Lleva': 24, 'Luego': 25, 'Max': 26, 'Más': 27, 'Por': 28, 'Se': 29, 'Su': 30, 'También': 31, 'Tiene': 32, 'Todo': 33, 'Todos': 34, 'Título': 35, 'Un': 36, 'Vive': 37, 'a': 38, 'abre': 39, 'acompaña': 40, 'al': 41, 'amigos': 42, 'animados': 43, 'aprende': 44, 'aprender': 45, 'arroz': 46, 'ayuda': 47, 'años': 48, 'baño': 49, 'bebe': 50, 'beso': 51, 'bien': 52, 'blanco': 53, 'buen': 54, 'buena': 55, 'busca': 56, 'cama': 57, 'cara': 58, 'casa': 59, 'cena': 60, 'cepilla': 61, 'cierra': 62, 'clases': 63, 'cocina': 64, 'cola': 65, 'come': 66, 'comer': 67, 'con': 68, 'contar': 69, 'contentos': 70, 'corre': 71, 'cosas': 72, 'cuaderno': 73, 'da': 74, 'de': 75, 'desayuno': 76, 'despierta': 77, 'dibujos': 78, 'dice': 79, 'dientes': 80, 'difícil': 81, 'divierten': 82, 'duerme': 83, 'día': 84, 'días': 85, 'el': 86, 'ella': 87, 'en': 88, 'entra': 89, 'es': 90, 'esconde': 91, 'escribir': 92, 'escuela': 93, 'estoy': 94, 'está': 95, 'están': 96, 'estás': 97, 'familia': 98, 'feliz': 99, 'gracias': 100, 'gustan': 101, 'hace': 102, 'hambre': 103, 'hasta': 104, 'hija': 105, 'jardín': 106, 'juega': 107, 'juntos': 108, 'la': 109, 'lado': 110, 'lanza': 111, 'las': 112, 'lava': 113, 'le': 114, 'leche': 115, 'leer': 116, 'levanta': 117, 'libros': 118, 'llama': 119, 'los': 120, 'lápiz': 121, 'maestra': 122, 'mamá': 123, 'mesa': 124, 'mira': 125, 'mochila': 126, 'mucha': 127, 'muchas': 128, 'mucho': 129, 'mueve': 130, 'muy': 131, 'niña': 132, 'niños': 133, 'noche': 134, 'noches': 135, 'nueve': 136, 'ocho': 137, 'ojos': 138, 'orejas': 139, 'otra': 140, 'pan': 141, 'papá': 142, 'pelota': 143, 'pequeña': 144, 'pequeñas': 145, 'pero': 146, 'perro': 147, 'pijama': 148, 'poco': 149, 'pollo': 150, 'pone': 151, 'por': 152, 'porque': 153, 'prepara': 154, 'preparando': 155, 'que': 156, 'quiere': 157, 'recreo': 158, 'ríe': 159, 'ríen': 160, 'sale': 161, 'salta': 162, 'se': 163, 'siempre': 164, 'sienta': 165, 'siente': 166, 'silencio': 167, 'sol': 168, 'sonrisa': 169, 'sopa': 170, 'su': 171, 'sueña': 172, 'sus': 173, 'también': 174, 'tarde': 175, 'tarea': 176, 'televisión': 177, 'temprano': 178, 'terminar': 179, 'tiene': 180, 'todo': 181, 'un': 182, 'una': 183, 'va': 184, 've': 185, 'veces': 186, 'ventana': 187, 'vez': 188, 'vuelve': 189, 'y': 190, '—Buenas': 191, '—Estoy': 192, '—Yo': 193, '—dice': 194, '—pregunta': 195, '—responde': 196, '—¡Buenos': 197, '—¿Cómo': 198, '<|endoftext|>': 199, '<|unk|>': 200}\n"
     ]
    }
   ],
   "source": [
    "result=re.split(r'([,.:;?_!\"()\\']|--|\\s)',raw_text)\n",
    "result=[item.strip() for item in result if item.strip()]\n",
    "preprocessed=result\n",
    "all_tokens = sorted(list(set(preprocessed)))\n",
    "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "vocab = {token:integer for integer,token in enumerate(all_tokens)}\n",
    "vocab_size=len(all_tokens)\n",
    "print(vocab)\n",
    "int_to_str = {i:s for s,i in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b2ae4508-0f25-4056-b0c8-f5a539fc7b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class espanolTokenizerV2:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = { i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        preprocessed = [\n",
    "            item if item in self.str_to_int \n",
    "            else \"<|unk|>\" for item in preprocessed\n",
    "        ]\n",
    "\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        text = re.sub(r'\\s+([,.:;?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bf1f9fe9-467b-4fa1-b685-23f452d43e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "día <|endoftext|> Cómo\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'día <|endoftext|> <|unk|>'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = espanolTokenizerV2(vocab)\n",
    "\n",
    "text1 = \"día\"\n",
    "text2 = \"Cómo\"\n",
    "\n",
    "text = \" <|endoftext|> \".join((text1, text2))\n",
    "\n",
    "print(text)\n",
    "tokenizer.encode(text)\n",
    "tokenizer.decode(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bbf57b60-cd35-4541-ad47-eada7d4e9a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "día <|endoftext|> Cómo\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'día <|endoftext|> <|unk|>'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(text)\n",
    "tokenizer.encode(text)\n",
    "tokenizer.decode(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df52e1a-a327-4ece-b612-374135740d48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06773258-3507-43fa-813a-45fb912f2c48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
